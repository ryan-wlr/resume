#!/usr/bin/env python3
"""Test that we fixed the duplicate content issue in DOCX creation"""

import sys
import os
import tempfile
import shutil

# Add the current directory to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from resume_windows import ResumeOptimizer

def test_no_duplicates():
    """Test that storytelling DOCX doesn't have duplicate name/contact/education"""
    print("üîç Testing for duplicate content in storytelling DOCX...")
    
    # Create temp output directory
    temp_dir = tempfile.mkdtemp()
    print(f"Using temp directory: {temp_dir}")
    
    try:
        # Initialize optimizer
        optimizer = ResumeOptimizer()
        
        # Mock detected field
        optimizer.current_detected_field = 'ai_researcher'
        
        # Create mock results with narrative content
        mock_results = {
            '7_narrative_resume': """
CAREER STORY RESUME FOR AI RESEARCHER

üî¨ THE AI VISIONARY WHO TRANSFORMS DATA INTO INTELLIGENT SOLUTIONS

RYAN WEILER

CONTACT INFORMATION:
üìû (561) 906-2118 | ‚úâÔ∏è ryan_wlr@yahoo.com
üîó LinkedIn: https://www.linkedin.com/in/ryan-weiler-7a3119190/
üíª GitHub: https://github.com/ryan-wlr

PROFESSIONAL NARRATIVE:
As an innovative AI researcher with expertise in machine learning algorithms and neural networks, I bring a unique blend of theoretical knowledge and practical implementation skills to drive breakthrough solutions in artificial intelligence.

TECHNICAL COMPETENCIES:
‚Ä¢ Advanced Machine Learning & Deep Learning Frameworks (TensorFlow, PyTorch, Scikit-learn)
‚Ä¢ Neural Network Architectures (CNNs, RNNs, Transformers, GANs)
‚Ä¢ Natural Language Processing & Computer Vision Systems
‚Ä¢ Data Science Pipeline Development (Python, R, SQL)
‚Ä¢ Research Methodology & Statistical Analysis
‚Ä¢ Cloud Computing Platforms (AWS, Google Cloud, Azure)

PROFESSIONAL EXPERIENCE:
‚Ä¢ Led development of novel neural network architectures for image classification
‚Ä¢ Implemented state-of-the-art NLP models for sentiment analysis
‚Ä¢ Published research papers on reinforcement learning applications
‚Ä¢ Collaborated on interdisciplinary AI projects with academic institutions
‚Ä¢ Designed and deployed machine learning models in production environments
‚Ä¢ Conducted extensive experiments with hyperparameter optimization
‚Ä¢ Developed data preprocessing pipelines for large-scale datasets
‚Ä¢ Mentored junior researchers in machine learning methodologies
"""
        }
        
        # Create the DOCX
        optimizer.create_formatted_docx_resume(mock_results, temp_dir)
        
        # Check if DOCX was created
        docx_path = os.path.join(temp_dir, 'optimized_resume.docx')
        if os.path.exists(docx_path):
            print("‚úÖ DOCX created successfully")
            print(f"‚úÖ File size: {os.path.getsize(docx_path)} bytes")
            
            # Try to read the DOCX to check for basic content structure
            try:
                from docx import Document
                doc = Document(docx_path)
                
                # Count paragraphs
                total_paragraphs = len(doc.paragraphs)
                print(f"‚úÖ Total paragraphs: {total_paragraphs}")
                
                # Look for potential duplicate patterns
                content_lines = [p.text.strip() for p in doc.paragraphs if p.text.strip()]
                
                # Check for duplicate names
                name_count = sum(1 for line in content_lines if 'Ryan' in line and 'Weiler' in line)
                print(f"‚úÖ Name occurrences: {name_count} (should be 1)")
                
                # Check for duplicate contact info
                contact_count = sum(1 for line in content_lines if '(561) 906-2118' in line)
                print(f"‚úÖ Contact info occurrences: {contact_count} (should be 1)")
                
                # Check for duplicate education headers
                edu_header_count = sum(1 for line in content_lines if line == 'Education')
                print(f"‚úÖ Education header occurrences: {edu_header_count} (should be 1)")
                
                # Print first few content lines for verification
                print("\nüìÑ First 10 content lines:")
                for i, line in enumerate(content_lines[:10]):
                    print(f"  {i+1}. {line}")
                
                if name_count <= 1 and contact_count <= 1 and edu_header_count <= 1:
                    print("\nüéâ SUCCESS: No duplicate content detected!")
                else:
                    print("\n‚ùå WARNING: Potential duplicate content found")
                    
            except ImportError:
                print("‚ö†Ô∏è  python-docx not available for content verification")
                
        else:
            print("‚ùå DOCX file was not created")
            
    except Exception as e:
        print(f"‚ùå Error during testing: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        # Clean up
        try:
            shutil.rmtree(temp_dir)
            print(f"üóëÔ∏è  Cleaned up temp directory: {temp_dir}")
        except:
            pass

if __name__ == "__main__":
    test_no_duplicates()